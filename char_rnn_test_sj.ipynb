{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn import rnn_cell\n",
    "from tensorflow.models.rnn import seq2seq\n",
    "\n",
    "import collections\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from six.moves import cPickle\n",
    "\n",
    "cwd=os.getcwd() \n",
    "sys.path.append(cwd)\n",
    "\n",
    "from Hangulpy.Hangulpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is for loading TEXT!\n",
    "class TextLoader():\n",
    "    def __init__(self, data_dir, batch_size, seq_length):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        input_file = os.path.join(data_dir, \"input.txt\")\n",
    "        vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n",
    "        tensor_file = os.path.join(data_dir, \"data.npy\")\n",
    "\n",
    "        if not (os.path.exists(vocab_file) and os.path.exists(tensor_file)):\n",
    "            print(\"reading text file\")\n",
    "            self.preprocess(input_file, vocab_file, tensor_file)\n",
    "        else:\n",
    "            print(\"loading preprocessed files\")\n",
    "            self.load_preprocessed(vocab_file, tensor_file)\n",
    "        self.create_batches()\n",
    "        self.reset_batch_pointer()\n",
    "\n",
    "    def preprocess(self, input_file, vocab_file, tensor_file):\n",
    "        with open(input_file, \"r\") as f:\n",
    "            data = f.read()\n",
    "        counter = collections.Counter(data)\n",
    "        count_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
    "        self.chars, _ = zip(*count_pairs)\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
    "        with open(vocab_file, 'wb') as f:\n",
    "            cPickle.dump(self.chars, f)\n",
    "        self.tensor = np.array(list(map(self.vocab.get, data)))\n",
    "        np.save(tensor_file, self.tensor)\n",
    "\n",
    "    def load_preprocessed(self, vocab_file, tensor_file):\n",
    "        with open(vocab_file, 'rb') as f:\n",
    "            self.chars = cPickle.load(f)\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
    "        self.tensor = np.load(tensor_file)\n",
    "        self.num_batches = int(self.tensor.size / (self.batch_size *\n",
    "                                                   self.seq_length))\n",
    "\n",
    "    def create_batches(self):\n",
    "        self.num_batches = int(self.tensor.size / (self.batch_size *\n",
    "                                                   self.seq_length))\n",
    "        self.tensor = self.tensor[:self.num_batches * self.batch_size * self.seq_length]\n",
    "        xdata = self.tensor\n",
    "        ydata = np.copy(self.tensor)\n",
    "        ydata[:-1] = xdata[1:]\n",
    "        ydata[-1] = xdata[0]\n",
    "        self.x_batches = np.split(xdata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
    "        self.y_batches = np.split(ydata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
    "\n",
    "\n",
    "    def next_batch(self):\n",
    "        x, y = self.x_batches[self.pointer], self.y_batches[self.pointer]\n",
    "        self.pointer += 1\n",
    "        return x, y\n",
    "\n",
    "    def reset_batch_pointer(self):\n",
    "        self.pointer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading preprocessed files\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Load text \n",
    "batch_size  = 50\n",
    "seq_length  = 50\n",
    "data_dir    = \"data/han2\"\n",
    "#data_dir    = \"data/han2\"\n",
    "#data_dir    = \"data/han3\"\n",
    "#data_dir    = \"data/han4\"\n",
    "#data_dir    = \"data/han5\"\n",
    "\n",
    "data_loader = TextLoader(data_dir, batch_size, seq_length)\n",
    "print (\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Ready\n"
     ]
    }
   ],
   "source": [
    "# Define Network \n",
    "rnn_size   = 1024\n",
    "num_layers = 2\n",
    "grad_clip  = 5.\n",
    "\n",
    "_batch_size = 1\n",
    "_seq_length = 1\n",
    "\n",
    "vocab_size = data_loader.vocab_size\n",
    "\n",
    "# Select RNN Cell\n",
    "unitcell = rnn_cell.BasicLSTMCell(rnn_size)\n",
    "cell = rnn_cell.MultiRNNCell([unitcell] * num_layers)\n",
    "\n",
    "# Set paths to the graph \n",
    "input_data = tf.placeholder(tf.int32, [_batch_size, _seq_length])\n",
    "targets    = tf.placeholder(tf.int32, [_batch_size, _seq_length])\n",
    "initial_state = cell.zero_state(_batch_size, tf.float32)\n",
    "\n",
    "# Set Network\n",
    "with tf.variable_scope('rnnlm'):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size])\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])\n",
    "        inputs = tf.split(1, _seq_length, tf.nn.embedding_lookup(embedding, input_data))\n",
    "        inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "# Loop function for seq2seq\n",
    "def loop(prev, _):\n",
    "    prev = tf.nn.xw_plus_b(prev, softmax_w, softmax_b)\n",
    "    prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "    return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "# Output of RNN \n",
    "outputs, last_state = seq2seq.rnn_decoder(inputs, initial_state, cell, loop_function=None, scope='rnnlm')\n",
    "output = tf.reshape(tf.concat(1, outputs), [-1, rnn_size])\n",
    "logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "# Next word probability \n",
    "probs = tf.nn.softmax(logits)\n",
    "# Define LOSS\n",
    "loss = seq2seq.sequence_loss_by_example([logits], # Input\n",
    "    [tf.reshape(targets, [-1])], # Target\n",
    "    [tf.ones([_batch_size * _seq_length])], # Weight \n",
    "    vocab_size)\n",
    "# Define Optimizer\n",
    "cost = tf.reduce_sum(loss) / _batch_size / _seq_length\n",
    "final_state = last_state\n",
    "lr = tf.Variable(0.0, trainable=False)\n",
    "tvars = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "_optm = tf.train.AdamOptimizer(lr)\n",
    "optm = _optm.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "print (\"Network Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sampling function \n",
    "def sample( sess, chars, vocab, __probs, num=200, prime=u'ㅇㅗᴥㄴㅡㄹᴥ '):\n",
    "    # state = cell.zero_state(1, tf.float32).eval()\n",
    "    state = sess.run(cell.zero_state(1, tf.float32))\n",
    "    _probs = __probs\n",
    "    \n",
    "    prime = list(prime)\n",
    "\n",
    "    for char in prime[:-1]:\n",
    "        x = np.zeros((1, 1))\n",
    "        x[0, 0] = vocab[char]\n",
    "        feed = {input_data: x, initial_state:state}\n",
    "        [state] = sess.run([final_state], feed)\n",
    "\n",
    "    def weighted_pick(weights):\n",
    "        t = np.cumsum(weights)\n",
    "        s = np.sum(weights)\n",
    "        return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "    ret = prime\n",
    "    char = prime[-1]\n",
    "    for n in range(num):\n",
    "        x = np.zeros((1, 1))\n",
    "        x[0, 0] = vocab[char]\n",
    "        feed = {input_data: x, initial_state:state}\n",
    "        [_probsval, state] = sess.run([_probs, final_state], feed)\n",
    "        p = _probsval[0]\n",
    "        # sample = int(np.random.choice(len(p), p=p))\n",
    "        sample = weighted_pick(p)\n",
    "        pred = chars[sample]\n",
    "        ret += pred\n",
    "        char = pred\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prime Text : 세상은 => ㅅㅔᴥㅅㅏㅇᴥㅇㅡㄴᴥ\n",
      "(u'\\u1d25', u' ', u'\\u3147', u'\\u314f', u'\\u3134', u'\\u3131', u'\\u3139', u'\\u3163', u'\\u3161', u'\\u3153', u'\\u3137', u'\\u3145', u'\\u3157', u'\\u3141', u'\\u3148', u'\\u314e', u'\\u315c', u'\\u3142', u'\\n', u'\\r', u'\\u3154', u'\\u3155', u'\\u3150', u'\\u3146', u'.', u'\\u314a', u'\\u3162', u'\\u314c', u'\\u3158', u'\\u314d', u',', u'\\u3132', u'\"', u'\\u315b', u'\\u3138', u'\\u315a', u'\\u3151', u'\\u314b', u'\\u315f', u'\\u315d', u'\\u3136', u'\\u3144', u'\\u3160', u'\\u3156', u'?', u'\\u3149', u'\\u3143', u\"'\", u'1', u')', u'(', u'\\u3159', u'!', u'-', u'0', u'2', u'\\u313a', u'3', u'5', u'9', u'\\u313b', u'\\u3135', u'\\u3140', u'4', u'e', u'6', u'8', u'7', u'a', u'\\u3152', u'i', u'n', u'o', u'>', u'\\u313c', u'<', u'r', u':', u't', u's', u'l', u'\\u315e', u']', u'[', u'h', u'm', u'`', u'c', u'S', u'd', u'u', u'A', u'p', u'C', u'T', u'g', u'I', u'B', u'y', u'M', u'D', u'P', u'f', u'E', u'^', u'*', u'L', u'N', u'R', u'\\u3133', u'O', u'k', u'K', u'b', u'V', u'H', u'_', u'F', u'J', u'v', u'=', u'\\u313e', u'G', u'/', u'w', u'~', u'%', u'W', u'Y', u'U', u'X', u'@', u'z', u'\\xb7', u'x', u'#', u'Z', u';', u'\\t', u'}', u'\\u313d', u'{', u'\\u313f', u'+', u'Q', u'j', u'\\x02', u'|', u'\\x19', u'q', u'\\x01', u'&', u'\\xf7', u'\\xd7', u'\\x1a', u'$', u'\\xb1', u'\\xad', u'\\\\', u'\\xb0', u'\\xae', u'\\xbd', u'\\xaa', u'\\xb4', u'\\xc6', u'\\x1c', u'\\xe6', u'\\xa7', u'\\x03', u'\\x1f', u'\\x0e', u'\\xb2', u'\\xb6', u'\\x0c', u'\\x18', u'\\xb3', u'\\x17', u'\\x1b', u'\\xa8', u'\\x7f', u'\\x06', u'\\x12', u'\\xa1', u'\\x1d', u'\\xfe')\n",
      "{u'\\x0c': 173, u'\\x18': 174, u'\\x1c': 165, u' ': 1, u'$': 155, u'\\xa7': 167, u'(': 50, u',': 30, u'0': 54, u'\\xb3': 175, u'\\u3132': 31, u'4': 63, u'\\xb7': 133, u'\\u3136': 40, u'8': 66, u'\\u313a': 56, u'<': 75, u'\\u313e': 121, u'@': 131, u'\\u3142': 17, u'D': 100, u'\\u3146': 23, u'H': 115, u'\\u314a': 25, u'L': 106, u'\\u314e': 15, u'P': 101, u'\\u3152': 69, u'T': 94, u'\\xd7': 153, u'\\u3156': 43, u'X': 130, u'\\u315a': 35, u'\\\\': 158, u'\\u315e': 81, u'`': 86, u'\\u3162': 26, u'd': 89, u'h': 84, u'l': 80, u'p': 92, u't': 78, u'\\xf7': 152, u'x': 134, u'|': 147, u'\\x03': 168, u'\\x17': 176, u'\\x1b': 177, u'\\x1f': 169, u'#': 135, u'\\u1d25': 0, u\"'\": 47, u'\\xa8': 178, u'+': 143, u'/': 123, u'\\u3131': 5, u'\\xb0': 159, u'3': 57, u'\\u3135': 61, u'\\xb4': 163, u'7': 67, u'\\u3139': 6, u';': 137, u'\\u313d': 140, u'?': 44, u'\\u3141': 13, u'C': 93, u'\\u3145': 11, u'G': 122, u'\\u3149': 45, u'K': 112, u'\\u314d': 29, u'O': 110, u'\\u3151': 36, u'S': 88, u'\\u3155': 21, u'W': 127, u'\\u3159': 51, u'[': 83, u'\\u315d': 39, u'_': 116, u'\\u3161': 8, u'c': 87, u'g': 95, u'k': 111, u'o': 72, u's': 79, u'w': 124, u'{': 141, u'\\x7f': 179, u'\\x02': 146, u'\\x06': 180, u'\\n': 18, u'\\x0e': 170, u'\\x12': 181, u'\\x1a': 154, u'\\xa1': 182, u'\"': 32, u'&': 151, u'*': 105, u'\\xad': 157, u'.': 24, u'\\xb1': 156, u'2': 55, u'\\u3134': 4, u'6': 65, u'\\u3138': 34, u':': 77, u'\\xbd': 161, u'\\u313c': 74, u'>': 73, u'\\u3140': 62, u'B': 97, u'\\u3144': 41, u'F': 117, u'\\u3148': 14, u'J': 118, u'\\u314c': 27, u'N': 107, u'\\u3150': 22, u'R': 108, u'\\u3154': 20, u'V': 114, u'\\u3158': 28, u'Z': 136, u'\\u315c': 16, u'^': 104, u'\\u3160': 42, u'b': 113, u'f': 102, u'j': 145, u'n': 71, u'r': 76, u'v': 119, u'z': 132, u'~': 125, u'\\x01': 150, u'\\t': 138, u'\\r': 19, u'\\x19': 148, u'\\x1d': 183, u'!': 52, u'%': 126, u')': 49, u'\\xaa': 162, u'-': 53, u'\\xae': 160, u'1': 48, u'\\u3133': 109, u'\\xb2': 171, u'5': 58, u'\\u3137': 10, u'\\xb6': 172, u'9': 59, u'\\u313b': 60, u'=': 120, u'\\u313f': 142, u'A': 91, u'\\u3143': 46, u'E': 103, u'\\u3147': 2, u'\\xc6': 164, u'I': 96, u'\\u314b': 37, u'M': 99, u'\\u314f': 3, u'Q': 144, u'\\u3153': 9, u'U': 129, u'\\u3157': 12, u'Y': 128, u'\\u315b': 33, u']': 82, u'\\u315f': 38, u'a': 68, u'\\u3163': 7, u'e': 64, u'\\xe6': 166, u'i': 70, u'm': 85, u'q': 149, u'u': 90, u'y': 98, u'}': 139, u'\\xfe': 184}\n",
      "save/model.ckpt-5000\n",
      "\n",
      "SAMPLED TEXT = [u'\\u3145', u'\\u3154', u'\\u1d25', u'\\u3145', u'\\u314f', u'\\u3147', u'\\u1d25', u'\\u3147', u'\\u3161', u'\\u3134', u'\\u1d25', u' ', u'\\u3137', u'\\u314f', u'\\u3134', u'\\u1d25', u'\\u3148', u'\\u3153', u'\\u3134', u'\\u1d25', u'\\u3148', u'\\u3153', u'\\u3131', u'\\u1d25', u'\\u3147', u'\\u3163', u'\\u3134', u'\\u1d25', u' ', u'\\u3145', u'\\u3153', u'\\u1d25', u'\\u3139', u'\\u3157', u'\\u1d25', u' ', u'\\u3131', u'\\u3153', u'\\u3134', u'\\u1d25', u'\\u3142', u'\\u3163', u'\\u1d25', u'\\u3134', u'\\u314f', u'\\u1d25', u' ', u'\\u314b', u'\\u3163', u'\\u1d25', u'\\u314a', u'\\u3155', u'\\u1d25', u' ', u'\\u3147', u'\\u3163', u'\\u3146', u'\\u1d25', u'\\u3147', u'\\u3153', u'\\u3146', u'\\u1d25', u'\\u3131', u'\\u3163', u'\\u1d25', u' ', u'\\u3138', u'\\u3150', u'\\u1d25', u'\\u3141', u'\\u315c', u'\\u3134', u'\\u1d25', u'\\r', u'\\n', u'\\u3147', u'\\u3163', u'\\u3134', u'\\u1d25', u'\\u3131', u'\\u314f', u'\\u1d25', u' ', u'\\u314e', u'\\u314f', u'\\u1d25', u'\\u3148', u'\\u3163', u'\\u1d25', u'\\u3141', u'\\u314f', u'\\u3134', u'\\u1d25', u' ', u'\\u3134', u'\\u3153', u'\\u3141', u'\\u1d25', u'\\u3131', u'\\u3155', u'\\u3146', u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u1d25', u'.', u' ', u'\\u3131', u'\\u3161', u'\\u1d25', u' ', u'\\u3141', u'\\u314f', u'\\u3139', u'\\u1d25', u'\\u3147', u'\\u3161', u'\\u1d25', u'\\u3139', u'\\u3157', u'\\u1d25', u' ', u'\\u3148', u'\\u3157', u'\\u314e', u'\\u1d25', u'\\u3147', u'\\u314f', u'\\u1d25', u'\\u314e', u'\\u314f', u'\\u1d25', u'\\u3134', u'\\u3161', u'\\u3134', u'\\u1d25', u'\\u3137', u'\\u3154', u'\\u1d25', u',', u' ', u'\\u3148', u'\\u3153', u'\\u3131', u'\\u1d25', u'\\u3134', u'\\u314f', u'\\u3134', u'\\u1d25', u' ', u'\\u3147', u'\\u314f', u'\\u1d25', u'\\u3148', u'\\u315c', u'\\u1d25', u' ', u'\\u3147', u'\\u3163', u'\\u1d25', u'\\u3141', u'\\u3163', u'\\u1d25', u' ', u'\\u3148', u'\\u3150', u'\\u1d25', u'\\u3143', u'\\u314f', u'\\u1d25', u'\\u3139', u'\\u3161', u'\\u3134', u'\\u1d25', u' ', u'\\u3141', u'\\u3163', u'\\u1d25', u'\\u3131', u'\\u315c', u'\\u3131', u'\\u1d25', u' ', u'\\r', u'\\n', u'\\u3147', u'\\u315d', u'\\u3134', u'\\u1d25', u'7', u'\\u3147', u'\\u3163', u'\\u3139', u'\\u1d25', u' ', u'\\u3142', u'\\u314f', u'\\u3134', u'\\u1d25', u'\\u3137', u'\\u3150', u'\\u1d25', u'\\u3147', u'\\u3162', u'\\u1d25', u' ', u'\\u3147', u'\\u3151', u'\\u3147', u'\\u1d25', u'\\u3142', u'\\u315c', u'\\u1d25', u'\\u3139', u'\\u3161', u'\\u3139', u'\\u1d25', u' ', u' ', u'\\u3148', u'\\u315c', u'\\u3147', u'\\u1d25', u'\\u3145', u'\\u3163', u'\\u3141', u'\\u1d25', u'\\u314e', u'\\u314f', u'\\u3134', u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u1d25', u'.', u'\\r', u'\\n', u' ', u' ', u'\\u3131', u'\\u3161', u'\\u1d25', u'\\u3139', u'\\u3153', u'\\u314e', u'\\u1d25', u'\\u3131', u'\\u3154', u'\\u1d25', u' ', u'\\u3141', u'\\u314f', u'\\u3139', u'\\u1d25', u'\\u314e', u'\\u3150', u'\\u3146', u'\\u1d25', u'\\u3134', u'\\u3161', u'\\u3134', u'\\u1d25', u'\\u3148', u'\\u3163', u'\\u1d25', u'\\u3137', u'\\u3157', u'\\u1d25', u' ', u'\\u3147', u'\\u3163', u'\\u1d25', u'\\u3148', u'\\u3153', u'\\u3134', u'\\u1d25', u'\\u3147', u'\\u3154', u'\\u1d25', u' ', u'\\u3137', u'\\u3150', u'\\u1d25', u'\\u314e', u'\\u314f', u'\\u3142', u'\\u1d25', u'\\u3142', u'\\u3163', u'\\u1d25', u'\\u3147', u'\\u3154', u'\\u1d25', u' ', u'\\u3147', u'\\u3155', u'\\u1d25', u'\\u314e', u'\\u314f', u'\\u3147', u'\\u1d25', u'\\u3141', u'\\u314f', u'\\u3139', u'\\u1d25', u'\\u3147', u'\\u3163', u'\\u1d25', u' ', u'\\u3137', u'\\u314f', u'\\u1d25', u'\\u3131', u'\\u3150', u'\\u1d25', u'\\u3134', u'\\u3154', u'\\u1d25', u' ', u'\\u3137', u'\\u315a', u'\\u1d25', u'\\u3147', u'\\u3153', u'\\u3146', u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u1d25', u'.', u' ', u'\\u3131', u'\\u3161', u'\\u1d25', u'\\u3139', u'\\u3161', u'\\u3139', u'\\u1d25', u' ', u'\\u3137', u'\\u3157', u'\\u3147', u'\\u1d25', u'\\u3145', u'\\u3153', u'\\u1d25', u' ', u'\\u3147', u'\\u314f', u'\\u3134', u'\\u1d25', u'\\u3147', u'\\u3154', u'\\u1d25', u'\\u3145', u'\\u3153', u'\\u1d25', u' ', u'\\u3137', u'\\u3157', u'\\u3139', u'\\u1d25', u'\\u3147', u'\\u314f', u'\\u1d25', u'\\u3134', u'\\u3150', u'\\u1d25', u'\\u3131', u'\\u3163', u'\\u1d25', u' ', u'\\u3147', u'\\u315f', u'\\u1d25', u'\\u314e', u'\\u3150', u'\\u1d25', u'\\u3145', u'\\u3153', u'\\u1d25', u'\\u3134', u'\\u3161', u'\\u3134', u'\\u1d25', u' ', u'\\u3148', u'\\u314f', u'\\u1d25', u'\\u3134', u'\\u3161', u'\\u3134', u'\\u1d25', u' ', u'\\u3131', u'\\u3157', u'\\u1d25', u'\\u3131', u'\\u3153', u'\\u3134', u'\\u1d25', u'\\u3147', u'\\u3163', u'\\u1d25', u'\\u3131', u'\\u3154', u'\\u1d25', u' ', u'\\r', u'\\n', u'\\u314e', u'\\u3150', u'\\u3146', u'\\u1d25', u'\\u3147', u'\\u3153', u'\\u3146', u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u1d25', u'.', u'\\r', u'\\n', u' ', u' ', u'I', u'm', u'a', u'r', u'm', u'a', u'n', u'o', u'l', u' ', u'M', u'e', u'r', u' ', u' ', u' ', u'\\u3147', u'\\u3161', u'\\u3139', u'\\u1d25', u'\\u3139', u'\\u3163', u'\\u1d25', u' ', u'\\u3147', u'\\u315f', u'\\u1d25', u'\\u3147', u'\\u3154', u'\\u1d25', u'\\u3131', u'\\u3154', u'\\u1d25', u' ', u'\\u3141', u'\\u3157', u'\\u3131', u'\\u1d25', u'\\u3147', u'\\u3161', u'\\u1d25', u'\\u3139', u'\\u3157', u'\\u1d25', u' ', u'\\u3141', u'\\u314f', u'\\u1d25', u'\\u3147', u'\\u3161', u'\\u3141', u'\\u1d25', u'\\u3147', u'\\u3161', u'\\u3139', u'\\u1d25', u' ', u'\\u3147', u'\\u3155', u'\\u3139', u'\\u1d25', u'\\u3139', u'\\u3163', u'\\u3139', u'\\u1d25', u' ', u'\\u314c', u'\\u314f', u'\\u1d25', u'\\u3131', u'\\u3157', u'\\u1d25', u'\\u3141', u'\\u314f', u'\\u3134', u'\\u1d25', u'\\u3147', u'\\u3163', u'\\u3134', u'\\u1d25', u' ', u'\\u3148', u'\\u314f', u'\\u1d25', u'\\u3131', u'\\u3161', u'\\u3131', u'\\u1d25', u' ', u'\\u3142', u'\\u315c', u'\\u1d25', u'\\u3147', u'\\u3163', u'\\u3134', u'\\u1d25', u'\\u3147', u'\\u3161', u'\\u3139', u'\\u1d25', u' ', u'\\u3137', u'\\u315f', u'\\u3145', u'\\u1d25', u'\\u3148', u'\\u314f', u'\\u3147', u'\\u1d25', u'\\u3131', u'\\u315c', u'\\u3134', u'\\u1d25', u'\\u3137', u'\\u3157', u'\\u1d25', u' ', u'\\u3142', u'\\u3157', u'\\u1d25', u'\\u3141', u'\\u3155', u'\\u3134', u'\\u1d25', u' ', u'\\u3131', u'\\u3163', u'\\u1d25', u'\\u3147', u'\\u3153', u'\\u3131', u'\\u1d25', u'\\u314a', u'\\u3153', u'\\u1d25', u'\\u3139', u'\\u3153', u'\\u3141', u'\\u1d25', u' ', u'\\u3131', u'\\u3153', u'\\u3131', u'\\u1d25', u'\\u3148', u'\\u3153', u'\\u3147', u'\\u1d25', u'\\r', u'\\n', u'\\u314e', u'\\u314f', u'\\u1d25', u'\\u3134', u'\\u3161', u'\\u3134', u'\\u1d25', u' ', u'\\u3147', u'\\u315b', u'\\u1d25', u'\\u3139', u'\\u3163', u'\\u1d25', u'\\u314a', u'\\u3163', u'\\u1d25', u'\\u3147', u'\\u3158', u'\\u1d25', u' ', u'\\u3131', u'\\u314f', u'\\u314c', u'\\u1d25', u'\\u3147', u'\\u3161', u'\\u3134', u'\\u1d25', u' ', u'\\u314e', u'\\u3155', u'\\u3142', u'\\u1d25', u'\\u3145', u'\\u3153', u'\\u3131', u'\\u1d25', u'\\u3147', u'\\u3163', u'\\u1d25', u' ', u'\\u3131', u'\\u314f', u'\\u1d25', u'\\u3132', u'\\u314f', u'\\u1d25', u'\\u3147', u'\\u315c', u'\\u3134', u'\\u1d25', u' ', u'\\u314a', u'\\u315c', u'\\u3147', u'\\u1d25', u'\\u3137', u'\\u3157', u'\\u3147', u'\\u1d25', u'\\u3145', u'\\u3153', u'\\u3147', u'\\u1d25', u'\\u3147', u'\\u3162', u'\\u1d25', u' ', u'\\u3137', u'\\u3150', u'\\u1d25', u'\\u3145', u'\\u314f', u'\\u3147', u'\\u1d25', u'\\u3142', u'\\u3157', u'\\u3134', u'\\u1d25', u'\\u3137', u'\\u3161', u'\\u3139', u'\\u1d25', u'\\u3147', u'\\u3163', u'\\u1d25', u' ', u'\\u3145', u'\\u3163', u'\\u1d25', u'\\u3137', u'\\u3157', u'\\u1d25', u'\\u3145', u'\\u3163', u'\\u1d25', u' ', u'\\u3131', u'\\u3157', u'\\u1d25', u'\\r', u'\\n', u'\\u3145', u'\\u3163', u'\\u3139', u'\\u1d25', u'\\u3145', u'\\u3163', u'\\u1d25', u'\\u314b', u'\\u3163', u'\\u1d25', u'\\u3139', u'\\u3155', u'\\u1d25', u' ', u'\\u314e', u'\\u314f', u'\\u3134', u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u1d25', u'.', u' ', u'\\u3147', u'\\u314f', u'\\u1d25', u'\\u3141', u'\\u315c', u'\\u1d25', u'\\u3139', u'\\u3163', u'\\u1d25', u' ', u'\\u314e', u'\\u315f', u'\\u1d25', u'\\u3137', u'\\u3161', u'\\u3145', u'\\u1d25', u'\\u3147', u'\\u3163', u'\\u1d25', u'\\u3131', u'\\u3157', u'\\u1d25', u' ', u'\\u3142', u'\\u3157', u'\\u1d25', u'\\u3147', u'\\u315d', u'\\u3146', u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u1d25', u')', u'\\r', u'\\n', u'\\u3134', u'\\u3161', u'\\u3134', u'\\u1d25', u' ', u'\\u3142', u'\\u3163', u'\\u314a', u'\\u1d25', u'\\u3131', u'\\u3158', u'\\u1d25', u' ', u' ', u'\\u3147', u'\\u314f', u'\\u1d25', u'\\u3134', u'\\u3161', u'\\u3139', u'\\u1d25', u'\\u3131', u'\\u3158', u'\\u1d25', u' ', u'\\u3131', u'\\u314f', u'\\u1d25', u'\\u3137', u'\\u3157', u'\\u3147', u'\\u1d25', u'\\u3131', u'\\u3158', u'\\u1d25', u' ', u'\\u3148', u'\\u3163', u'\\u3142', u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u3134', u'\\u1d25', u'\\u3147', u'\\u3163', u'\\u1d25', u' ', u'\\u3148', u'\\u3163', u'\\u1d25', u'\\u3134', u'\\u3150', u'\\u3139', u'\\u1d25', u' ', u'\\u3145', u'\\u315c', u'\\u1d25', u' ', u'\\u3147', u'\\u3163', u'\\u3146', u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u1d25', u'\\r', u'\\n', u'\\u3134', u'\\u3161', u'\\u3134', u'\\u1d25', u' ', u'\\u3142', u'\\u314f', u'\\u3131', u'\\u1d25', u'\\u3145', u'\\u314f', u'\\u1d25', u'\\u3147', u'\\u3158', u'\\u1d25', u' ', u'\\u314e', u'\\u314f', u'\\u3141', u'\\u1d25', u'\\u3132', u'\\u3154', u'\\u1d25', u' ', u'\\u314c', u'\\u3153', u'\\u3131', u'\\u1d25', u'\\u3142', u'\\u314f', u'\\u3147', u'\\u1d25', u'\\u3147', u'\\u3161', u'\\u3139', u'\\u1d25', u' ', u'\\u3137', u'\\u3157', u'\\u3139', u'\\u1d25', u'\\u3139', u'\\u3155', u'\\u3146', u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u1d25', u'.', u' ', u'\\u3148', u'\\u314f', u'\\u1d25', u'\\u3139', u'\\u3163', u'\\u1d25', u'\\u3147', u'\\u3154', u'\\u1d25', u'\\u3145', u'\\u3153', u'\\u1d25', u' ', u'\\u3141', u'\\u314f', u'\\u3136', u'\\u1d25', u'\\u3147', u'\\u3161', u'\\u3134', u'\\u1d25', u'\\r', u'\\n', u'\\u3148', u'\\u314f', u'\\u1d25', u'\\u3131', u'\\u3155', u'\\u3131', u'\\u1d25', u')', u'\\u3147', u'\\u3161', u'\\u3139', u'\\u1d25', u' ', u'\\u3131', u'\\u314f', u'\\u1d25', u'\\u3134', u'\\u3161', u'\\u3147', u'\\u1d25', u'\\u314e', u'\\u314f', u'\\u3134', u'\\u1d25', u' ', u'\\u3131', u'\\u3153', u'\\u3145', u'\\u1d25', u'\\u3147', u'\\u3163', u'\\u1d25', u'\\u3131', u'\\u3157', u'\\u1d25', u' ', u'\\u3139', u'\\u3150', u'\\u3134', u'\\u1d25', u'\\u3145', u'\\u3153', u'\\u3134', u'\\u1d25', u'\\u3147', u'\\u3162', u'\\u1d25', u' ', u'\\u3147', u'\\u3159', u'\\u1d25', u'\\u3141', u'\\u3163', u'\\u1d25', u'\\u314b', u'\\u3155', u'\\u1d25', u'\\u3138', u'\\u3150', u'\\u1d25', u'\\u3139', u'\\u3163', u'\\u3134', u'\\u1d25', u' ', u'\\u314b', u'\\u3161', u'\\u1d25', u'\\u3131', u'\\u3154', u'\\u1d25', u' ', u'\\u3145', u'\\u3163', u'\\u1d25', u'\\u3145', u'\\u3153', u'\\u3134', u'\\u1d25', u'\\u3147', u'\\u3161', u'\\u3139', u'\\u1d25', u' ', u'\\u3141', u'\\u315d', u'\\u1d25', u'\\u3145', u'\\u3153', u'\\u1d25', u'\\r', u'\\n', u'\\u3147', u'\\u3155', u'\\u314d', u'\\u1d25', u'\\u3147', u'\\u3155', u'\\u3146', u'\\u1d25', u'\\u3137', u'\\u314f', u'\\u1d25', u'.', u' ', u'\\u3147', u'\\u3153', u'\\u3144', u'\\u1d25', u'\\u3134', u'\\u3161', u'\\u3134', u'\\u1d25', u' ', u'\\u3134', u'\\u3150', u'\\u1d25', u'\\u3147', u'\\u3154', u'\\u1d25', u' ', u'\\u314d', u'\\u3163', u'\\u1d25', u'\\u314a', u'\\u3163', u'\\u1d25', u'\\u3137', u'\\u3153', u'\\u1d25']\n",
      "\n",
      "-- RESULT --\n",
      "세상은 단전적인 서로 건비나 키쳐 있었기 때문\n",
      "인가 하지만 넘겼다. 그 말으로 좋아하는데, 적난 아주 이미 재빠른 미국 \n",
      "원7일 반대의 양부를  중심한다.\n",
      "  그렇게 말했는지도 이전에 대합비에 여항말이 다개네 되었다. 그를 동서 안에서 돌아내기 위해서는 자는 고건이게 \n",
      "했었다.\n",
      "  Imarmanol Mer   을리 위에게 목으로 마음을 열릴 타고만인 자극 부인을 뒷장군도 보면 기억처럼 걱정\n",
      "하는 요리치와 같은 협석이 가까운 충동성의 대상본들이 시도시 고\n",
      "실시키려 한다. 아무리 휘듯이고 보웠다)\n",
      "는 빛과  아늘과 가동과 집단이 지낼 수 있다\n",
      "는 박사와 함께 턱방을 돌렸다. 자리에서 많은\n",
      "자격)을 가능한 것이고 랜선의 왜미켜때린 크게 시선을 뭐서\n",
      "옆였다. 없는 내에 피치더\n"
     ]
    }
   ],
   "source": [
    "# Sample ! \n",
    "save_dir = \"save\"\n",
    "prime = decompose_text(u\"세상은\")\n",
    "print (\"Prime Text : %s => %s\" % (automata(prime), \"\".join(prime)))\n",
    "\n",
    "n = 1000\n",
    "with open(os.path.join(save_dir, 'config.pkl'), 'rb') as f:\n",
    "    saved_args = cPickle.load(f)\n",
    "with open(os.path.join(save_dir, 'chars_vocab.pkl'), 'rb') as f:\n",
    "    chars, vocab = cPickle.load(f)\n",
    "\n",
    "print chars\n",
    "print vocab\n",
    "    \n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "saver = tf.train.Saver(tf.all_variables())\n",
    "ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "\n",
    "print (ckpt.model_checkpoint_path)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    sampled_text = sample(sess, chars, vocab, probs, n, prime)\n",
    "    print (\"\")\n",
    "    print (u\"SAMPLED TEXT = %s\" % sampled_text)\n",
    "\n",
    "    print (\"\")\n",
    "    print (\"-- RESULT --\")\n",
    "    print (automata(\"\".join(sampled_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
